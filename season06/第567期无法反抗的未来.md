<audio src="http://igetoss.cdn.igetget.com/mp3/201808/27/201808272052148598014778.mp3" controls="controls">您的浏览器不支持 audio 标签。</audio><p>和你一起终身学习，这里是罗辑思维。</p><p>今天继续跟你聊尤瓦尔·赫拉利的新作《今日简史》。</p><p>昨天我们说到，现实取决于共识。这是尤瓦尔赫拉利三本书一以贯之的角度。这跟我们的日常直觉正好相反。传统上一般以为，人脑子里的认识是跟着外部世界的现实变的。但尤瓦尔·赫拉利偏偏要说，真相也许是，人类脑子里的共识才造就外部的现实。里面的共识一变，外面现实就全变。当然哲学史上一直有这么一派观点。</p><p>为什么赫拉利总是强调这一点？因为只有强调这一点，才能看清楚我们这代人站在一个什么样的人类文明的转折点上。</p><p>你想，过去一万年，人类不管发明什么工具，从轮子弓箭到汽车飞机，本质上都是对人类体力的替代和强化，技术对于我们大脑的反作用非常有限。</p><p>所以我们在一直技术进步中感受到的都是好事，比如效率、方便、力量。所以不管过去一万年，我们怎么感慨人类文明沧海桑田，变化剧烈，那种变化还是缓慢的，渐进的，平滑的，方向清晰的。</p><p>但是现在不同了，现在的技术，尤其是人工智能和生物技术，它们开始突破我们身体的边界，要进入我们脑子里了，要像黑客黑入一个网络一样，黑进我们的大脑内部了。技术要参与塑造我们意识、认识和整个人类的共识，这给人类文明带来的不确定性，和变化的剧烈程度，是过去一万年很难想象的。</p><p>说到这儿，你就明白为什么尤瓦尔·赫拉利要反复强调，是人类的共识决定现实了。这是人类第一次真切地感受到自己亲生的孩子，就是技术，现在长大了，进入了青春反抗期，不仅要脱离亲生父母父母的控制，而且要反过来控制亲身父母了。所以我们这代人生活在人类文明的一个转折期。</p><p>你可能会说，不对吧？技术只是我们的工具，人类的想法还是我们自己的啊。</p><p>我们来看尤瓦尔·赫拉利举的一个例子。假设你是一个抽烟的人，现代科学已经告诉你了，抽烟有害健康。但是很多人还是忍不住要抽。他们明知这不是一件好事情。但是他们觉得，身体是我的，我自己冒风险，我是用自由意志来决定要不要损害我自己身体的，别人管不着。好，在未来生物技术和人工智能技术的背景下，他们这份任性，还能不能继续下去。</p><p>比如说，某一天，装在抽烟的人的身体里的生物传感器明确警告他：“刚刚在你的肺里面检测到17个癌细胞，你要是继续抽烟的话，情况会更严重。”</p><p>好，如果他不搭理它，继续抽。生物传感器就会把这个数据传给他的妻子、母亲、孩子。还要传给他的公司领导。领导也许没那么关心他的身体健康，但是公司的系统会自动记录这是一个不听劝告的人，是一个对自己的身体都不太在乎的人，公司对他未来的工作表现就多了一个问号。还没完，生物传感器还会把这个数据，发给他的保险公司，他的健康保险就会涨价，直到没有保险公司愿意卖保险给他。</p><p>你看，在这种情况下，他还能决定自己的想法和行为吗？他是被新技术监控的，原来被隔绝开的那些社会压力排山倒海地来了，已经身不由己。</p><p>你可能会说，这不是好事么？这是抑制抽烟啊。那吃饭呢？如果你每一顿饭都有人按照卡路里、脂肪摄入的严格标准来监控你，一旦过量就会被认为生活方式不健康或者意志薄弱，就会影响你在各个方面的社会信用。你不觉得人生被剥夺了很多乐趣，我们的自由意志连吃饭这种事都不能自己做主了？</p><p>那你可能会说，太可怕了，我不装这生物传感器行不行吗？不装不行啊。不是谁逼你装，是你自己要装的。你就想，未来的医疗系统就是这个样子的，没有这些传感器，医生没法给你看病，保险公司没法卖给你保险。就像现在你到医院去，害怕X光机带来的辐射，拒绝照X光一样，医院是没法给你提供医疗服务的。未来也是一样，你为了救命，你只好装上生物传感器。</p><p>很多科幻小说，都把人工智能掌控的世界描述得很可怕，好像突然崛起了一个人类的敌人，要处心积虑地消灭人类。但是在尤瓦尔·赫拉利看来，根本不用等到那一天，人类早就把自己交出去了。</p><p>如果把人类和人工智能之间的博弈看成一场战争。这场战争没得打，因为这是一场没有防守线的战争，没有人类可以发起反击的战场啊，因为每一步都是人类自己主动退让的。</p><p>不说那么远，就说现在，大家都用闹钟吧？为啥？就是怕自己在规定的时刻醒不了，我们需要一个外在的力量来干涉我们自己的行动。我自己年轻时候觉就特别多，甚至买过一个闹钟，它是带轮子的，一旦响起来之后，就马上就在屋里乱滚，甚至滚到床底下，你要是不起床，就没办法把它拿出来，不能让它停下来。你看，我们人类多么渴望有外在的力量来干涉自己的行动。</p><p>比如，将来有一种药，吃了之后，注意力就可以更加集中，学习和工作效率会更高，你吃不吃？这可不是科幻啊，这种药现在已经出现了，小范围内已经有很多人在服用。如果这种药合法，我自己肯定马上就吃。为啥？我就恨自己读书工作的时候，经常被各种心猿意马打断嘛，我需要这种外来的强制力。如果这种药的技术成熟了，你就想去吧，得有多少家长、老师劝自己的孩子吃这种药。</p><p>再比如说，我叫罗胖，减了半辈子的肥，也不怎么成功。如果有一种技术，可以短暂切断我大脑对身体的感知，你说我会不会买这个服务？当然会买啊。这样，我的身体每天就可以在跑步机上跑一两个小时，而我的大脑完全感受不到身体有氧运动带来的痛苦，我的大脑可以看书，可以看美剧。减肥大业就要成啊。你就想去吧，这个服务要是在技术上可靠了，得多受欢迎。</p><p>以上说的这些技术，有的远有的近，但是你可以看得出来，我们人类对于自己的自由意志其实没有那么重视。在我们需要的那些方向上，我们其实会主动地，甚至是争前恐后地把对自己的决定权交出去的。所以人工智能技术不用像科幻小说里面，演化到面目狰狞的份儿上，想要害人类，根本不需要，它只要按照现有的轨迹向前发展，人类文化就会面临一个巨大的转向。人类的意志不再是这个世界演化的依据。</p><p>举个例子，现在的广告业，不管多么神乎其神，多么抓住人类意志薄弱的弱点来推送信息，最终买不买的决定权还是掌握在顾客自己手里的，你得来骗我买。</p><p>但是数据技术演化到将来，我们会最终放弃决策权。比如你要买车，你的人工智能助手会告诉你，根据你现在的预算，驾驶能力、周边路况、趣味偏好，以及其他复杂维度的数据分析，你就应该买这款车，这是数据和智能推荐你的。你说你听不听？如果你听了，或者很多人听了，那么汽车广告这么大一个行业就没有用了。因为没有必要说服你，它说服数据就行了。</p><p>尤瓦尔·赫拉利还举了一个自己的例子。每次他出书的时候，出版社都会请他写一个简短的介绍，用于网络宣传。但出版社会把他写的文字改成迎合谷歌算法的版本。出版社会建议他：“不要用这个词，换成那个词比较好，那个词能在谷歌算法里得到更多的关注。”</p><p>你看，只要抓住了算法的目光，抓住人类的目光就是自然而然的事了。这样一来，整个世界运行，互动和反馈的基础，不再是人，而是算法。</p><p>这是一万年人类文明史上，我们从来没有面对过的情况，我们能适应这么大的变化吗？</p><p>明天我们接着来聊这个话题。</p><p>《今日简史》这本书的精排版电子书，在得到App全球首发，特价优惠还有最后两天，看见我们的未来，建议你收藏一本。</p><p>罗辑思维，明天见。</p><img src="https://piccdn.igetget.com/img/201808/27/201808272055469684909292.jpg" />